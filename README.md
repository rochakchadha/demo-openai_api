# demo-openai_api
 Basic code to demo a LLM based chatbot using openai models or a local LLM running with an openai style API. 
 The local LLM must be deployed with an openai style API. We use https://github.com/lm-sys/FastChat for this.
Follow the steps on https://github.com/lm-sys/FastChat#install to setup the fastchat from source on your GPU node(s) or cluster. Then follow the steps here https://github.com/lm-sys/FastChat/blob/main/docs/openai_api.md to deploy. 

