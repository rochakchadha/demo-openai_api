{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"EMPTY\"\n",
    "openai.api_base = \"http://172.29.40.143:8000/v1\"\n",
    "#openai.api_base = \"http://20.159.217.84:9000/v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>System Message Cell</B>: This cell will contain the system message which defines the behavior of the chatbot. This is a fixed message and usually doesn't change between different chat sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\"\n",
    "    #\"content\": \"You are a rude and obnoxious assistant. Answer as that.\"\n",
    "    #\"content\": \"You are a helpful, and honest assitant. Below is a text from a research paper. Format the text correctly and reply with the formatted text. If the text does not make any sense or is just a bibliography or a table, summarize the text instead.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>User Prompt Cell</b>: In this cell, users can input their message. You can leave this cell empty or with a basic structure, and users can modify the content as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_content = \"Table 3: Eﬀect of early retirement on number of days in hospital during ﬁve years of follow up, for the early retirees, and 95% conﬁdence intervals. The ﬁrst year Women n=106437 Men n=104459 naive −0.396 DRcnn DRmlp −0.062 ORds −0.135 DRss −0.138 DRds −0.128 tmle −0.143 The second year naive −0.354 DRcnn −0.082 DRmlp −0.083 ORds −0.104 DRss −0.098 DRds −0.081 tmle −0.111 The third year DRcnn DRmlp naive −0.277 ORds −0.034 DRss −0.018 DRds −0.010 tmle −0.018 The fourth year naive −0.179 DRcnn DRmlp ORds DRss DRds tmle The ﬁfth year naive −0.232 DRcnn −0.012 DRmlp −0.979 ORds −0.019 DRss −0.013 DRds tmle −0.014 −0.167 0.183) −0.037 (−0.060, (−0.192, 0.069) (−0.231, −0.039) (−0.232, −0.045) (−0.222, −0.035) (−0.237, −0.049) n=105776 −0.192 0.067) (−0.231, 0.058) (−0.224, 0.007) −0.007 (−0.215, 0.011) (−0.207, (−0.190, 0.027) (−0.220, −0.002) n=105039 0.175) 0.370) 0.124) 0.138) 0.146) 0.139) −0.173 −0.216 0.315) 2.040) −0.517 0.250) −0.032 0.259) −0.016 0.273) −0.008 0.251) −0.015 −0.230 0.161) −0.095 1.024) −0.153 0.132) −0.050 0.137) −0.035 0.151) −0.029 0.136) −0.034 (−0.153, ( 0.029, (−0.192, (−0.174, (−0.167, (−0.174, n=104293 (−0.181, (−0.432, (−0.186, (−0.176, (−0.162, (−0.185, n=103477 (−0.185, (−2.982, (−0.169, (−0.163, (−0.150, (−0.164, (−0.256, 0.183) (−0.079, 0.355) (−0.156, 0.192) (−0.148, 0.199) (−0.145, 0.202) (−0.156, 0.192)\"\n",
    "user_content = \"The quick brown fox jumps over the lazy dog. Where does this sentence originate from?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = {\"role\": \"user\", \"content\": user_content}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Chat Execution Cell</b>: This cell will send the request to the chat model and print the response. Users can run this cell every time they want to send a new message. It will use the <u>user_message</u> variable from the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello! I'm here to help you with your question. The sentence \"The quick brown fox jumps over the lazy dog\" is often referred to as the \"pangram,\" which means it contains all the letters of the alphabet in a single sentence. This sentence is often used as a demonstration of a font or typing test, as it includes every letter of the alphabet at least once.\n",
      "\n",
      "Unfortunately, I couldn't find the origin of this sentence. It's possible that it was coined by a linguist or a typographer as a way to demonstrate the range of letters in a particular font or language. However, I couldn't find any definitive information on its origin. I hope that helps! If you have any further questions, feel free to ask.\n"
     ]
    }
   ],
   "source": [
    "# works on openai ver 0.28\n",
    "messages = [system_message, user_message]\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"Llama-2-7b-chat-hf\",\n",
    "    temperature=0.9,\n",
    "    max_tokens=1024,\n",
    "    messages=messages,\n",
    "    stream=True,\n",
    ")\n",
    "#pretty print the response\n",
    "for chunk in response:\n",
    "    content = chunk[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n",
    "    print(content, end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This sentence is known as a pangram, which is a sentence that uses every letter of the alphabet at least once. It has been in use since the early days of printing presses, and its exact origin is uncertain. However, it's a popular phrase used to test the functionality of typewriters and print settings. The phrase \"The quick brown fox jumps over the lazy dog\" is just one of many pangrams that have been used throughout history.\n"
     ]
    }
   ],
   "source": [
    "#for openai ver > 1.0\n",
    "from openai import OpenAI\n",
    "\n",
    "messages = [system_message, user_message]\n",
    "#client = OpenAI(api_key=\"EMPTY\", base_url=\"http://172.29.40.143:8000/v1\")\n",
    "client = OpenAI(api_key=\"EMPTY\", base_url=\"http://20.159.217.84:9000/v1\")\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    #model=\"Llama-2-7b-chat-hf\",\n",
    "    model = \"Mistral-7B-Instruct-v0.2\",\n",
    "    messages=messages,\n",
    "    stream=True,\n",
    ")\n",
    "#print(response.choices[0].message.content)\n",
    "for chunk in response:\n",
    "    try:\n",
    "        content = chunk.choices[0].delta.content\n",
    "        if content is None:\n",
    "            content = \"\"\n",
    "    except Exception as e:\n",
    "        content = chunk.choices[0].delta.get(\"content\", \"\")\n",
    "    print(content, end=\"\", flush=True)\n",
    "print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
